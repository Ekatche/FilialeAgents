# ğŸ” Analyse Technique du Code pour le Tracking des CoÃ»ts

**Date** : 2025-10-25
**Status** : Analyse complÃ©tÃ©e âœ…

---

## ğŸ“‹ Architecture du SystÃ¨me d'Extraction

### Flux d'exÃ©cution actuel

```
1. extraction_core.py::extract_company_data()
   â†“
2. orchestrate_extraction() [orchestrator/extraction_orchestrator.py]
   â†“
3. agent_caller.py::call_*_agent()
   â†“
4. agent_wrappers.py::run_agent_with_metrics()
   â†“
5. Runner.run(agent, input, max_turns)
   â†“
6. result (avec potentiellement result.usage)
```

### Agents exÃ©cutÃ©s sÃ©quentiellement

1. **ğŸ” Ã‰claireur** (Company Analyzer) - `gpt-4o-mini`
2. **â›ï¸ Mineur** (Information Extractor) - `gpt-4o-mini`
3. **ğŸ—ºï¸ Cartographe** (Subsidiary Extractor) - `gpt-4o` + `gpt-4o-search-preview` OU `sonar-pro`
4. **âš–ï¸ Superviseur** (Meta Validator) - `gpt-4o`
5. **ğŸ”„ Restructurateur** (Data Restructurer) - `gpt-4o`

---

## âœ… Ce qui existe dÃ©jÃ 

### 1. SystÃ¨me de MÃ©triques (metrics/)

- **AgentMetrics** : Track le temps, Ã©tapes, statut
- **performance_metrics** : Dictionnaire extensible pour donnÃ©es custom
- **run_agent_with_metrics()** : Wrapper qui execute les agents

### 2. Service de Tracking des CoÃ»ts

- `cost_tracking_service.py` : Calcul des coÃ»ts basÃ© sur tokens
- `ModelPricing` : Prix par modÃ¨le (gpt-4o, gpt-4o-mini, etc.)
- `calculate_extraction_cost()` : Fonction principale de calcul

### 3. Base de DonnÃ©es

Table `company_extractions` avec colonnes :
```python
cost_usd: Float
cost_eur: Float
total_tokens: Integer
input_tokens: Integer
output_tokens: Integer
models_usage: JSONB
```

### 4. Frontend

- `ExtractionCostCard.tsx` : Composant dÃ©jÃ  crÃ©Ã© âœ…
- IntÃ©grÃ© dans `results-page.tsx` âœ…
- Hook `useCosts` pour API âœ…

---

## ğŸ¯ Points d'Injection pour le Tracking

### Point 1 : Capture des tokens dans run_agent_with_metrics()

**Fichier** : `api/company_agents/metrics/agent_wrappers.py`
**Ligne** : ~123 (aprÃ¨s `result = await Runner.run(...)`)

**Action** :
```python
# AprÃ¨s l'exÃ©cution de l'agent
result = await Runner.run(agent, input=current_input, max_turns=max_turns)

# AJOUTER : Capturer les tokens si disponibles
if hasattr(result, 'usage') and result.usage:
    agent_metrics.performance_metrics["tokens"] = {
        "model": agent.model if hasattr(agent, 'model') else "unknown",
        "input_tokens": result.usage.prompt_tokens,
        "output_tokens": result.usage.completion_tokens,
        "total_tokens": result.usage.total_tokens
    }
```

### Point 2 : Retourner les tokens dans agent_caller.py

**Fichier** : `api/company_agents/orchestrator/agent_caller.py`
**Fonctions** : `call_company_analyzer`, `call_information_extractor`, etc.

**Action** : Modifier pour retourner non seulement le rÃ©sultat mais aussi les mÃ©triques (ou enrichir ExtractionState)

### Point 3 : AgrÃ©ger dans orchestrate_extraction()

**Fichier** : `api/company_agents/orchestrator/extraction_orchestrator.py`
**Ligne** : ~200 (avant le return final)

**Action** :
```python
# AJOUTER : RÃ©cupÃ©rer les mÃ©triques de tous les agents
all_models_usage = []

# RÃ©cupÃ©rer les tokens de chaque agent
analyzer_metrics = metrics_collector.get_agent_metrics("ğŸ” Ã‰claireur", session_id)
if analyzer_metrics and "tokens" in analyzer_metrics.performance_metrics:
    all_models_usage.append(analyzer_metrics.performance_metrics["tokens"])

# ... mÃªme chose pour les autres agents

# Ajouter au rÃ©sultat final
result["models_usage_raw"] = all_models_usage
```

### Point 4 : Calculer et sauvegarder dans extraction_core.py

**Fichier** : `api/company_agents/extraction_core.py`
**Ligne** : ~79 (aprÃ¨s ajout des metadata, avant le return)

**Action** :
```python
# AJOUTER : Calculer les coÃ»ts
from services.cost_tracking_service import cost_tracking_service

if "models_usage_raw" in result:
    cost_data = cost_tracking_service.calculate_extraction_cost(
        result["models_usage_raw"]
    )

    # Ajouter les coÃ»ts au rÃ©sultat
    result["extraction_costs"] = {
        "cost_usd": cost_data["total_cost_usd"],
        "cost_eur": cost_data["total_cost_eur"],
        "total_tokens": cost_data["total_tokens"],
        "input_tokens": cost_data["total_input_tokens"],
        "output_tokens": cost_data["total_output_tokens"],
        "models_breakdown": cost_data["models_breakdown"],
        "search_type": "advanced" if deep_search else "simple"
    }
```

### Point 5 : Sauvegarder en DB dans status_manager

**Fichier** : `api/status.py` ou `api/services/agent_tracking_service.py`
**Fonction** : `store_extraction_results()` ou Ã©quivalent

**Action** : Enrichir l'enregistrement `CompanyExtraction` avec les donnÃ©es de coÃ»t

---

## ğŸš§ ProblÃ¨me Potentiel

**L'API OpenAI Agents ne retourne peut-Ãªtre pas `result.usage`**

### Solution A : VÃ©rifier si result.usage existe
```python
if hasattr(result, 'usage') and result.usage:
    # Capturer les tokens
else:
    logger.warning(f"âš ï¸ Pas de donnÃ©es d'usage pour {agent_name}")
```

### Solution B : Utiliser un callback sur les appels API
Si `Runner.run()` ne retourne pas l'usage, il faut instrumenter au niveau des appels directs Ã  l'API OpenAI.

### Solution C : Estimation basÃ©e sur tiktoken
En dernier recours, estimer les tokens avec la bibliothÃ¨que `tiktoken`.

---

## ğŸ“ Plan d'ImplÃ©mentation

### Ã‰tape 1 : Test de capture des tokens

1. Modifier `run_agent_with_metrics()` pour logger `result.__dict__`
2. Lancer une extraction de test
3. VÃ©rifier si `usage` est prÃ©sent dans le rÃ©sultat

### Ã‰tape 2A : Si usage est disponible

1. âœ… Modifier `run_agent_with_metrics()` pour capturer les tokens
2. âœ… Modifier `orchestrate_extraction()` pour agrÃ©ger
3. âœ… Modifier `extraction_core.py` pour calculer et stocker
4. âœ… Modifier le stockage DB pour sauvegarder les coÃ»ts

### Ã‰tape 2B : Si usage n'est pas disponible

1. Instrumenter les appels directs Ã  l'API OpenAI
2. Utiliser un callback/middleware pour capturer les tokens
3. Alternatives : tiktoken pour estimation

### Ã‰tape 3 : Liaison avec la DB

1. Identifier oÃ¹ `CompanyExtraction` est crÃ©Ã©/updatÃ©
2. Ajouter les champs de coÃ»t lors de la sauvegarde
3. Associer au `session_id`

### Ã‰tape 4 : VÃ©rification Frontend

1. Tester l'endpoint `/costs/extraction/session/{session_id}`
2. VÃ©rifier que le frontend affiche les donnÃ©es
3. Valider les montants

---

## ğŸ”‘ Fichiers ClÃ©s Ã  Modifier

| Fichier | Action | PrioritÃ© |
|---------|--------|----------|
| `metrics/agent_wrappers.py` | Capturer tokens dans performance_metrics | ğŸ”´ HAUTE |
| `orchestrator/extraction_orchestrator.py` | AgrÃ©ger tokens de tous les agents | ğŸ”´ HAUTE |
| `extraction_core.py` | Calculer coÃ»ts et ajouter au rÃ©sultat | ğŸ”´ HAUTE |
| `status.py` ou Ã©quivalent | Sauvegarder en DB | ğŸ”´ HAUTE |
| `services/agent_tracking_service.py` | Enrichir le tracking | ğŸŸ¡ MOYENNE |

---

## ğŸ¯ CritÃ¨res de SuccÃ¨s

- [ ] Les tokens sont capturÃ©s pour chaque agent
- [ ] Les coÃ»ts sont calculÃ©s correctement (USD + EUR)
- [ ] Les coÃ»ts sont sauvegardÃ©s dans `company_extractions`
- [ ] Le `session_id` est bien liÃ© aux coÃ»ts
- [ ] Le frontend affiche les coÃ»ts de la session
- [ ] Le type de recherche (simple/advanced) est stockÃ©

---

## ğŸ“Š Tests Ã  Effectuer

### Test 1 : Recherche Simple
```bash
# Lancer une recherche simple
# VÃ©rifier les logs pour voir les tokens capturÃ©s
# VÃ©rifier la DB : cost_eur devrait Ãªtre ~0.05-0.10â‚¬
```

### Test 2 : Recherche AvancÃ©e
```bash
# Lancer une recherche avec deep_search=true
# VÃ©rifier que sonar-pro est utilisÃ©
# VÃ©rifier la DB : cost_eur devrait Ãªtre ~0.20-0.50â‚¬
```

### Test 3 : Affichage Frontend
```bash
# Naviguer vers la page de rÃ©sultats
# VÃ©rifier que la ExtractionCostCard s'affiche
# VÃ©rifier les montants EUR et USD
# VÃ©rifier le dÃ©tail par modÃ¨le
```

---

## ğŸš€ Prochaine Ã‰tape

**Ã‰TAPE 1** : Tester si `result.usage` est disponible

Ajouter un log temporaire dans `run_agent_with_metrics()` :
```python
# Ligne ~123 aprÃ¨s result = await Runner.run(...)
logger.info(f"ğŸ” [DEBUG] result attributes: {dir(result)}")
logger.info(f"ğŸ” [DEBUG] result.__dict__: {result.__dict__}")
```

Lancer une extraction et analyser les logs.

---

**Document crÃ©Ã© le** : 2025-10-25
**Status** : PrÃªt pour implÃ©mentation
