# ğŸ¢ OpenAiAgents - Extraction d'Informations d'Entreprise

Ce projet contient des expÃ©rimentations et une API complÃ¨te pour l'extraction d'informations d'entreprise en utilisant OpenAI Agents.

## ğŸ“ Structure du Projet

```
OpenAiAgents/
â”œâ”€â”€ api/                                # ğŸš€ API FastAPI (backend)
â”‚   â”œâ”€â”€ main.py                         # EntrÃ©e ASGI
â”‚   â”œâ”€â”€ start.py                        # DÃ©marrage local
â”‚   â”œâ”€â”€ routers/                        # Routes FastAPI
â”‚   â”œâ”€â”€ services/                       # Services (tracking, validation, websocket)
â”‚   â”œâ”€â”€ company_agents/                 # Orchestrateur et agents
â”‚   â”‚   â”œâ”€â”€ extraction_core.py          # EntrÃ©e orchestrateur
â”‚   â”‚   â”œâ”€â”€ extraction_manager.py       # Orchestration Analyse â†’ Info â†’ Filiales â†’ Validation â†’ Restructuration
â”‚   â”‚   â”œâ”€â”€ models.py                   # SchÃ©mas Pydantic (CompanyInfo, SubsidiaryReport, ...)
â”‚   â”‚   â””â”€â”€ subs_agents/                # Agents: analyzer, info, subs, meta, restructurer
â”‚   â””â”€â”€ README.md                       # Doc API (si prÃ©sent)
â”œâ”€â”€ frontend/                           # ğŸŒ Frontend Next.js
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ clear-extraction-cache.sh       # Script utilitaire (optionnel)
â”œâ”€â”€ nginx/                              # Config Nginx (dÃ©ploiement)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ filialesAgents.ipynb            # ğŸ““ Notebook dâ€™expÃ©rimentation
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ pyproject.toml                      # DÃ©pendances gÃ©rÃ©es avec uv (pas de requirements.txt)
â””â”€â”€ uv.lock                             # Verrouillage des dÃ©pendances
```

## ğŸ¯ Objectifs

### ğŸ““ Notebooks d'ExpÃ©rimentation

- **EquipeAgents.ipynb** : ExpÃ©rimentations originales avec les agents OpenAI
- **EquipeAgents_Reorganise.ipynb** : Version rÃ©organisÃ©e et optimisÃ©e
- **filialesAgents.ipynb** : SpÃ©cialisation pour l'extraction de filiales

### ğŸš€ API de Production

- **api/** : API FastAPI complÃ¨te et prÃªte pour la production
- Extraction intelligente d'informations d'entreprise
- Support des filiales et relations parent-enfant
- **ğŸ›¡ï¸ SystÃ¨me de monitoring des quotas OpenAI** (Ã©vite les erreurs 429)
- **ğŸ“¦ Cache intelligent** pour rÃ©duire les coÃ»ts API
- **ğŸš¨ Alertes prÃ©ventives** pour les limites de quota

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis

- Python 3.11+ et uv (`pip install uv`)
- Node 18+ (pour le frontend)
- Docker (optionnel)

### Configuration

- Dupliquez `.env.example` en `.env` et renseignez les clÃ©s nÃ©cessaires (ex: `PERPLEXITY_API_KEY`, `OPENAI_API_KEY` si utilisÃ©).

### DÃ©marrage (Makefile recommandÃ©)

```bash
# Aide et installation
make help
make setup

# DÃ©marrer l'API puis le frontend
make start
make start-frontend

# VÃ©rifier les services
make status

# Ouvrir la documentation Swagger
make docs
```

### Endpoints principaux

- POST `http://localhost:8000/extract` (corps: `{ "company_name": "..." }`) â†’ `CompanyInfo`
- POST `http://localhost:8000/extract-from-url` (corps: `{ "url": "..." }`) â†’ `CompanyInfo`
- Docs Swagger: `http://localhost:8000/docs`

### Notes

- Le filtrage post-extraction est dÃ©sactivÃ© par dÃ©faut pour Ã©valuer lâ€™impact du prompt.
  - Voir `ENABLE_SUBS_FILTERS` dans `api/company_agents/extraction_manager.py`.
  - Passez Ã  `True` pour rÃ©activer les filtres (accessibilitÃ©/fraÃ®cheur â‰¤24 mois).

## ğŸ“š Documentation

- **API Documentation** : [api/README.md](api/README.md) - Documentation complÃ¨te de l'API
- **Swagger UI** : http://localhost:8000/docs (quand l'API est dÃ©marrÃ©e)

## ğŸ”§ Configuration

### Variables d'Environnement

```bash
export OPENAI_API_KEY="votre-cle-api-openai"
```

### DÃ©pendances

```bash
# Pour les notebooks
pip install jupyter notebook

# Pour l'API (uv)
uv sync
```

## ğŸ§ª Tests

### Tests de l'API

```bash
make test
make docs
```

### Tests manuels

```bash
# Health check
curl http://localhost:8000/health

# Extraction d'entreprise
curl -X POST "http://localhost:8000/extract" \
     -H "Content-Type: application/json" \
     -d '{"company_name": "Apple Inc."}'
```

## ğŸ“ˆ Ã‰volution du Projet

1. **Phase 1** : ExpÃ©rimentations dans les notebooks
2. **Phase 2** : RÃ©organisation et optimisation
3. **Phase 3** : Conversion en API FastAPI (âœ… TerminÃ©)
4. **Phase 4** : DÃ©ploiement et production

## ğŸ¤ Contribution

1. Utilisez les notebooks pour les expÃ©rimentations
2. Une fois validÃ©, intÃ©grez dans l'API
3. Testez avec les scripts fournis
4. Documentez les changements

## ğŸ“„ Licence

Ce projet est sous licence MIT.

## ğŸ†˜ Support

- **Issues** : [GitHub Issues](https://github.com/votre-repo/issues)
- **Documentation API** : [api/README.md](api/README.md)
- **Documentation Swagger** : http://localhost:8000/docs

## ğŸ“œ Plan minimal (orchestration multi-agents)

RÃ©sumÃ© dâ€™implÃ©mentation alignÃ© avec `api/company_agents/extraction_manager.py` et `plan_minimal.md`:

- SÃ©quence: Analyse â†’ Info â†’ Filiales â†’ Validation â†’ Restructuration
- CritÃ¨res (extraits):
  - `company_analyzer` dâ€™abord; fallback si `relationship="unknown"` ou sources vides.
  - `information_extractor` si info-clÃ©s manquantes/faible qualitÃ©.
  - `subsidiary_extractor` (TOP 10, sources officielles, fallback â€œprÃ©sences gÃ©ographiquesâ€ si 0 filiale).
  - `meta_validator` si incohÃ©rences (parent divergent, sources absentes, filiales non sourcÃ©es).
- Tracking: progression et warnings exposÃ©s via `agent_tracking_service`.
- FraÃ®cheur: prioritÃ© <24 mois (dÃ©sactivable via `ENABLE_SUBS_FILTERS`).
- Sortie finale: `CompanyInfo` (via restructurateur).

Voir le dÃ©tail: [`plan_minimal.md`](./plan_minimal.md).

## ğŸ¤– Agents (Ã©tat actuel)

- ğŸ” Ã‰claireur (`company_analyzer`)

  - RÃ´le: identifier lâ€™entitÃ© lÃ©gale, statut corporate (parent/subsidiary/independent), parent Ã©ventuel.
  - Outils: WebSearchTool
  - ModÃ¨le: gpt-4.1-mini
  - Sortie: `CompanyLinkage` (schÃ©ma strict)

- â›ï¸ Mineur (`information_extractor`)

  - RÃ´le: extraire la fiche dâ€™identitÃ© (siÃ¨ge, secteur, activitÃ©s, sources).
  - Outils: WebSearchTool
  - ModÃ¨le: gpt-4.1-mini
  - Sortie: `CompanyCard` (schÃ©ma strict)

- ğŸ—ºï¸ Cartographe (`subsidiary_extractor`)

  - RÃ´le: extraire les 10 principales filiales avec localisations et sources officielles; fallback â€œprÃ©sences gÃ©ographiquesâ€ si 0 filiale.
  - Outils: aucun (recherche intÃ©grÃ©e Sonar via Perplexity API Compatible OpenAI)
  - ModÃ¨le: sonar-pro (Perplexity), temperature=0.0, max_tokens=3200
  - Sortie: `SubsidiaryReport` (schÃ©ma strict)

- âš–ï¸ Superviseur (`meta_validator`)

  - RÃ´le: valider la cohÃ©rence globale, scorer (gÃ©ographie/structure/sources/overall), produire recommandations et warnings.
  - Outils: aucun
  - ModÃ¨le: gpt-4o-mini
  - Sortie: `MetaValidationReport` (schÃ©ma strict)

- ğŸ”„ Restructurateur (`data_restructurer`)
  - RÃ´le: normaliser les donnÃ©es en `CompanyInfo` final, sans champs additionnels, avec respect des limites (sources, GPS, etc.).
  - Outils: aucun
  - ModÃ¨le: gpt-4.1-mini
  - Sortie: `CompanyInfo` (schÃ©ma strict)
