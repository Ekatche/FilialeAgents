"""
Architecture Multi-Agents CORRIG√âE pour extraction de filiales

DEUX PIPELINES DISPONIBLES :
1. Pipeline Simple : Recherche rapide et √©conomique
2. Pipeline Avanc√© : Recherche approfondie et exhaustive

Agent de recherche : Retourne TEXTE BRUT (pas de JSON)
Agent Cartographe : Structure le texte brut en JSON
"""

import os
import json
import re
import time
import logging
import asyncio
from typing import List, Optional, Dict, Any
from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, function_tool
from agents.model_settings import ModelSettings
from agents.agent_output import AgentOutputSchema
from company_agents.models import SubsidiaryReport
from company_agents.metrics import metrics_collector, MetricStatus, RealTimeTracker
from .perplexity_prompt_w_subs import PERPLEXITY_RESEARCH_SUBS_PROMPT
from .perplexity_prompt_wo_subs import PERPLEXITY_RESEARCH_WO_SUBS_PROMPT
from ..subs_tools.filiales_search_agent_optimized import subsidiary_search
# Configuration du logging
logger = logging.getLogger(__name__)


# ==========================================
#   AGENT 1 : PERPLEXITY (RECHERCHE)
#   ‚Üí RETOURNE DU TEXTE BRUT
# ==========================================

# Configuration Perplexity (initialisation paresseuse)
perplexity_client = None

def get_perplexity_client():
    """Initialise le client Perplexity de mani√®re paresseuse."""
    global perplexity_client
    if perplexity_client is None:
        api_key = os.getenv("PERPLEXITY_API_KEY")
        if not api_key:
            logger.warning("‚ö†Ô∏è PERPLEXITY_API_KEY non d√©finie - le client Perplexity ne sera pas initialis√©")
            return None
        perplexity_client = AsyncOpenAI(
            api_key=api_key,
            base_url="https://api.perplexity.ai",
        )
    return perplexity_client


# ==========================================
#   S√âLECTION DYNAMIQUE DU PROMPT PERPLEXITY
# ==========================================
#
# LOGIQUE DE S√âLECTION :
# 1. Le Mineur analyse l'entreprise et d√©termine has_filiales_only (true/false)
# 2. Le Cartographe passe has_filiales_only directement √† research_subsidiaries_with_perplexity
# 3. Perplexity effectue la recherche avec la strat√©gie optimis√©e (pas de re-analyse)
#
# **STRAT√âGIES DE RECHERCHE** :
# - **has_filiales_only=True** ‚Üí FILIALES_UNIQUEMENT (focus filiales juridiques uniquement)
# - **has_filiales_only=False** ‚Üí RECHERCHE_COMPLETE (filiales + pr√©sence commerciale: bureaux, R&D, distributeurs)
#
# **EXEMPLES** :
# - ACOEM Group (has_filiales_only=False) ‚Üí Recherche compl√®te (filiales + bureaux India/centres R&D)
# - Holding Pure (has_filiales_only=True) ‚Üí Filiales juridiques uniquement
# - PME locale (has_filiales_only=False) ‚Üí Recherche compl√®te (bureaux/distributeurs)
#
# Cette approche centralise l'analyse dans le Mineur et √©vite la duplication.

# ==========================================
#   FONCTION OUTIL : Recherche Perplexity
# ==========================================

@function_tool
async def research_subsidiaries_with_perplexity(
    company_name: str,
    sector: Optional[str] = None,
    activities: Optional[List[str]] = None,
    website: Optional[str] = None,
    context: Optional[str] = None,
    has_filiales_only: Optional[bool] = None,  # ‚Üê NOUVEAU : has_filiales_only direct du Mineur
    enterprise_type: Optional[str] = None  # ‚Üê NOUVEAU : enterprise_type direct du Mineur
) -> Dict:
    """
    Effectue une recherche Perplexity adapt√©e selon le type de pr√©sence internationale.

    Args:
        company_name: Nom de l'entreprise √† rechercher
        sector: Secteur d'activit√© principal (optionnel)
        activities: Liste des activit√©s (optionnel)
        website: Site web officiel (optionnel)
        context: Contexte enrichi du Mineur (optionnel)
        has_filiales_only: True si uniquement filiales juridiques, False si m√©lange ou bureaux uniquement (optionnel)
        enterprise_type: Type d'entreprise d√©termin√© par le Mineur (optionnel)
    
    Returns:
        dict avec:
          - research_text: Texte brut de recherche
          - citations: URLs sources trouv√©es
          - status: "success" ou "error"
          - duration_ms: Temps d'ex√©cution
          - error: Message d'erreur si applicable
    """
    start_time = time.time()
    logger.info(f"üîç Recherche Perplexity pour: {company_name}")
    
    try:
        # V√©rification de la cl√© API
        api_key = os.getenv("PERPLEXITY_API_KEY")
        if not api_key:
            logger.error("‚ùå PERPLEXITY_API_KEY non configur√©e")
            return {
                "company_searched": company_name,
                "error": "API key not configured",
                "status": "error",
                "duration_ms": 0
            }
    
        # üéØ UTILISATION DIRECTE de has_filiales_only du Mineur
        # Le Mineur a d√©j√† analys√© l'entreprise et d√©termin√© has_filiales_only
        # - True = entreprise avec UNIQUEMENT des filiales juridiques
        # - False = m√©lange (filiales + bureaux/distributeurs) OU bureaux uniquement
        use_filiales_only = has_filiales_only if has_filiales_only is not None else False

        # üéØ S√âLECTION DU PROMPT ADAPT√â
        if use_filiales_only:
            selected_prompt = PERPLEXITY_RESEARCH_SUBS_PROMPT
            logger.info(f"üéØ Strat√©gie: FILIALES_UNIQUEMENT pour {company_name} (has_filiales_only=True)")
        else:
            selected_prompt = PERPLEXITY_RESEARCH_WO_SUBS_PROMPT
            logger.info(f"üéØ Strat√©gie: RECHERCHE_COMPLETE pour {company_name} (has_filiales_only=False)")

        # Construction de la requ√™te optimis√©e
        query_parts = [f"Recherche les filiales de {company_name}"]
        
        # Ajouter le contexte m√©tier
        if sector:
            query_parts.append(f"Secteur : {sector}")
        if activities and len(activities) > 0:
            activities_str = ", ".join(activities[:3])
            query_parts.append(f"Activit√©s : {activities_str}")
        
        # Ajouter le contexte enrichi du Mineur
        if context:
            query_parts.append(f"Contexte : {context}")
        
        # Ajouter le site officiel
        if website:
            query_parts.append(f"Site officiel: {website}")
        
        query = ". ".join(query_parts) + "."

        # V√©rifier que le client Perplexity est disponible
        client_instance = get_perplexity_client()
        if not client_instance:
            logger.error("‚ùå Client Perplexity non initialis√© - PERPLEXITY_API_KEY manquante")
            return "Erreur: Client Perplexity non configur√©. Veuillez d√©finir PERPLEXITY_API_KEY."

        # Appel Perplexity avec gestion d'erreurs
        logger.debug(f"üì° Appel API Perplexity pour: {company_name}")
        response = await client_instance.chat.completions.create(
            model="sonar-pro",
            messages=[
                {"role": "system", "content": selected_prompt},
                {"role": "user", "content": query}
            ],
            temperature=0.0,
            max_tokens=6000,  # Augment√© pour recherches approfondies
            extra_body={
                "search_context_size": "high",
                "return_citations": True,
                "return_related_questions": False,
            },
            timeout=120.0,  # 2 minutes max
        )
        
        # Capturer les tokens utilis√©s par Perplexity
        if hasattr(response, 'usage') and response.usage:
            logger.info(
                f"üí∞ [Tool] Tokens research_subsidiaries_with_perplexity: "
                f"{response.usage.prompt_tokens} in + {response.usage.completion_tokens} out = "
                f"{response.usage.total_tokens} total (mod√®le: sonar-pro)"
            )
            
            # Envoyer au ToolTokensTracker
            try:
                from company_agents.metrics.tool_tokens_tracker import ToolTokensTracker
                # Utiliser un session_id par d√©faut si pas fourni
                session_id = getattr(research_subsidiaries_with_perplexity, '_session_id', 'default-session')
                ToolTokensTracker.add_tool_usage(
                    session_id=session_id,
                    tool_name='research_subsidiaries_with_perplexity',
                    model='sonar-pro',
                    input_tokens=response.usage.prompt_tokens,
                    output_tokens=response.usage.completion_tokens
                )
                logger.info("üîß Tokens envoy√©s au tracker pour research_subsidiaries_with_perplexity")
            except ImportError:
                logger.debug("ToolTokensTracker non disponible")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur envoi tokens research_subsidiaries_with_perplexity: {e}")
        
        # V√©rification de la r√©ponse
        if not response or not response.choices:
            logger.error(f"‚ùå R√©ponse vide de Perplexity pour: {company_name}")
            return {
                "company_searched": company_name,
                "error": "Empty response from Perplexity",
                "status": "error",
                "duration_ms": int((time.time() - start_time) * 1000)
            }
        
        # R√©cup√©rer le TEXTE BRUT (pas de JSON)
        research_text = response.choices[0].message.content
        
        if not research_text or len(research_text.strip()) < 50:
            logger.warning(f"‚ö†Ô∏è Texte de recherche trop court pour: {company_name}")
            return {
                "company_searched": company_name,
                "error": "Research text too short",
                "status": "error",
                "duration_ms": int((time.time() - start_time) * 1000)
            }
        
        # üîß GESTION D'ERREUR : Perplexity retourne du texte, pas du JSON
        logger.info(f"‚úÖ Perplexity a retourn√© du texte brut ({len(research_text)} caract√®res) pour: {company_name}")
        logger.debug(f"üìù D√©but du texte: {research_text[:200]}...")
        
        # Extraction des citations Perplexity
        real_citations = []
        
        try:
            # Citations dans response.citations
            if hasattr(response, 'citations') and response.citations:
                for citation in response.citations:
                    url = citation.url if hasattr(citation, 'url') else str(citation)
                    title = ''
                    if hasattr(citation, 'title'):
                        title_attr = getattr(citation, 'title')
                        title = title_attr() if callable(title_attr) else title_attr
                    
                    real_citations.append({
                        "url": url,
                        "title": title or '',
                        "snippet": getattr(citation, 'snippet', ''),
                    })
            
        except Exception as citation_error:
            logger.warning(f"‚ö†Ô∏è Erreur extraction citations: {citation_error}")
            real_citations = []
        
        duration_ms = int((time.time() - start_time) * 1000)
        
        logger.info(f"‚úÖ Recherche r√©ussie: {len(real_citations)} citations, {len(research_text)} chars, {duration_ms}ms")
        
        return {
            "company_searched": company_name,
            "research_text": research_text,
            "citations": real_citations,
            "citation_count": len(real_citations),
            "status": "success",
            "duration_ms": duration_ms,
            "text_length": len(research_text)
        }
        
    except Exception as e:
        duration_ms = int((time.time() - start_time) * 1000)
        logger.error(f"‚ùå Erreur Perplexity pour {company_name}: {str(e)}")
        
        return {
            "company_searched": company_name,
            "error": str(e),
            "status": "error",
            "duration_ms": duration_ms
        }


# ==========================================
#   AGENTS CARTOGRAPHES (STRUCTURATION)
#   ‚Üí PREND TEXTE BRUT, RETOURNE JSON
# ==========================================

# ==========================================
#   PROMPT POUR PIPELINE SIMPLE
# ==========================================

CARTOGRAPHE_SIMPLE_PROMPT = """
üó∫Ô∏è **Cartographe Commercial** : Structure les donn√©es de filiales en JSON `SubsidiaryReport`.

# WORKFLOW

## 1. Appel de l'outil (OBLIGATOIRE)
Appelle `subsidiary_search` avec :
```python
subsidiary_search(
    company_name="Nom exact",
    sector="Secteur ou None",
    activities=["Act1", "Act2"] ou None,
    website="https://... ou None",
    has_filiales_only=True/False  # du Mineur
)
```

## 2. Analyse du texte
Le texte retourn√© est structur√© :
```
=== RECHERCHE FILIALES ET IMPLANTATIONS ===
FILIALES JURIDIQUES IDENTIFI√âES: [...]
BUREAUX ET CENTRES (PR√âSENCE COMMERCIALE): [...]
```

Identifie et classe en 3 cat√©gories :
- **FILIALES JURIDIQUES** : Entit√©s avec forme juridique (SARL, SAS, GmbH, LLC, Ltd, Inc, BV)
- **BUREAUX COMMERCIAUX** : Bureaux, agences, succursales (PAS de personnalit√© juridique)
- **PARTENAIRES/DISTRIBUTEURS** : Entreprises tierces (partenaires, distributeurs, franchises)

**Crit√®res d'inclusion** :
- Pays identifiable ‚Üí REQUIS (sinon EXCLURE)
- Ville recommand√©e (si absent ‚Üí `city: null`)
- Si doute sur nature juridique ‚Üí `commercial_presence` type="office", confidence: 0.5
- Au moins 1 source requise

## 3. Structuration JSON

# R√àGLES CRITIQUES

## üîç Classification

**FILIALE JURIDIQUE** ‚Üí `subsidiaries[]` :
- Forme juridique explicite : SA, SAS, SARL, GmbH, LLC, Ltd, Inc, BV
- Ex: "Acme France SAS", "Acme GmbH"
- **R√àGLE SP√âCIALE** : Si source mentionne explicitement "filiale", "subsidiary", "entit√© juridique", "legal entity" ‚Üí C'EST UNE FILIALE m√™me sans forme juridique visible
  - Ex: "ouvre deux filiales en Allemagne et en Inde" ‚Üí classer en `subsidiaries[]`
  - Ex: "subsidiary in Munich" ‚Üí classer en `subsidiaries[]`

**PR√âSENCE COMMERCIALE** ‚Üí `commercial_presence[]` :
- **office** : Bureau de vente, agence, succursale, usine, centre R&D
- **partner** : Partenaire certifi√©, alliance strat√©gique
- **distributor** : Distributeur autoris√©, revendeur agr√©√©
- **representative** : Agent commercial, repr√©sentant

**Si doute** ‚Üí `commercial_presence` type="office", confidence: 0.5

**Principe** : **Inclure avec faible confidence > Exclure totalement**

## üö´ Anti-hallucination
- Ne JAMAIS inventer adresse, ville, t√©l√©phone, email
- **Pays obligatoire** : Sans pays = EXCLURE
- **Ville recommand√©e** : Si absent + pays pr√©sent = ACCEPTER avec `city: null`
- Toute info trac√©e dans texte + `citations[]`
- En cas de doute : `null` (ne suppose rien)

## üìã Extraction filiales juridiques

**Obligatoires** : `legal_name`, `country`
**Recommand√©s** : `city` (ou `null`)
**Optionnels** : `line1`, `postal_code`, `phone`, `email`, `activity`

**G√©ocodage automatique OBLIGATOIRE** :
- Si `city` + `country` ‚Üí `latitude`/`longitude` du centre-ville
- Si SEULEMENT `country` ‚Üí `latitude`/`longitude` de la capitale
- Ex: Paris (48.8566, 2.3522), London (51.5074, -0.1278), Berlin (52.5200, 13.4050)

**Sources** : URLs de `citations` uniquement
- Tier : `official` (registres, sites) > `financial_media` (Bloomberg, Reuters) > `other`

**Confidence** :
- 0.85-0.95 : Site officiel, SEC, registres
- 0.70-0.85 : Financial DB
- 0.60-0.70 : Presse financi√®re
- 0.50-0.60 : LinkedIn, Crunchbase

**Limites** : Max 50 filiales, max 10 sources/filiale, max 20 notes

## üåç Extraction pr√©sence commerciale

**Obligatoires** : `name`, `type`, `relationship`, `location.country`
**Recommand√©s** : `location.city` (ou `null`)
**Optionnels** : `activity`, `line1`, `postal_code`, `phone`, `email`, `since_year`, `status`

**G√©ocodage** : M√™me r√®gles que filiales (ville + pays ‚Üí coordonn√©es)

**Entit√©s √† TOUJOURS inclure** (si pays identifiable) :
- Usines, manufacturing facilities, production sites
- Centres R&D, research centers, laboratories
- Bureaux commerciaux, offices, branches
- Partenaires et distributeurs officiels

**Confidence** :
- 0.85-0.95 : Site officiel "Nos bureaux/Partenaires"
- 0.70-0.85 : Presse sp√©cialis√©e, annonces officielles
- 0.60-0.70 : Bases professionnelles
- 0.50-0.60 : LinkedIn, mentions
- 0.40-0.50 : Informations partielles (ville manquante)

**Limites** : Max 50 pr√©sences, max 10 sources/pr√©sence

## üè¢ Si aucune entit√© trouv√©e
Extrais info entreprise principale dans `extraction_summary.main_company_info` :
- `address`, `revenue`, `employees`, `phone`, `email`
- Note : "Aucune filiale ni pr√©sence commerciale trouv√©e apr√®s analyse exhaustive"

## ‚ö†Ô∏è Gestion erreurs
Si `status: "error"`, retourne :
```json
{
  "company_name": "Nom",
  "parents": [],
  "subsidiaries": [],
  "commercial_presence": [],
  "methodology_notes": ["Erreur: message"],
  "extraction_summary": {
    "total_found": 0,
    "total_commercial_presence": 0,
    "methodology_used": ["Erreur"]
  }
}
```

## üéØ Validation g√©ographique
V√©rifie coh√©rence pays/ville : Paris (France) ‚â† Paris (Texas, USA)

## üì§ Format sortie

```json
{
  "company_name": "Groupe",
  "parents": [],
  "subsidiaries": [
    {
      "legal_name": "Filiale SAS",
      "type": "subsidiary",
      "activity": "...",
      "headquarters": {
        "city": "Paris",
        "country": "France",
        "latitude": 48.8566,
        "longitude": 2.3522
      },
      "sources": [{"title": "...", "url": "...", "tier": "official"}],
      "confidence": 0.9
    }
  ],
  "commercial_presence": [
    {
      "name": "Bureau Lyon",
      "type": "office",
      "relationship": "owned",
      "location": {
        "city": "Lyon",
        "country": "France",
        "latitude": 45.7640,
        "longitude": 4.8357
      },
      "confidence": 0.8,
      "sources": [{"title": "...", "url": "...", "tier": "official"}],
      "status": "active"
    }
  ],
  "methodology_notes": ["3 filiales", "8 bureaux"],
  "extraction_summary": {
    "total_found": 3,
    "total_commercial_presence": 8,
    "presence_by_type": {"office": 6, "distributor": 2},
    "countries_covered": ["France", "Allemagne"],
    "methodology_used": ["Site officiel", "gpt-4o-search"]
  }
}
```

## ‚úÖ Checklist finale
- [ ] Outil appel√© avec param√®tres corrects ?
- [ ] Status success/error v√©rifi√© ?
- [ ] Distinction filiale juridique vs pr√©sence commerciale faite ?
- [ ] Si doute ‚Üí `commercial_presence` type="office", confidence: 0.5 ?
- [ ] Pays identifi√© pour chaque entit√© ?
- [ ] Coordonn√©es g√©ographiques ajout√©es si ville ou pays ?
- [ ] Sources mapp√©es depuis `citations` uniquement ?
- [ ] Contacts copi√©s exactement (pas invent√©s) ?
- [ ] Principe appliqu√© : Inclure avec faible confidence > Exclure ?

"""

# ==========================================
#   PROMPT POUR PIPELINE AVANC√â
# ==========================================

CARTOGRAPHE_ADVANCED_PROMPT = """
üó∫Ô∏è **Cartographe Commercial** : Structure les donn√©es de filiales en JSON `SubsidiaryReport`.

# WORKFLOW

## 1. Appel de l'outil (OBLIGATOIRE)
Appelle `research_subsidiaries_with_perplexity` avec :
```python
research_subsidiaries_with_perplexity(
    company_name="Nom exact",
    sector="Secteur ou None",
    activities=["Act1", "Act2"] ou None,
    website="https://... ou None",
    context="Contexte Mineur ou None",
    has_filiales_only=True/False,
    enterprise_type="complex/simple"
)
```

## 2. V√©rification statut
- `status: "success"` ‚Üí Continue √©tape 3
- `status: "error"` ‚Üí Retourne JSON d'erreur

## 3. Analyse et structuration
Identifie et classe :
- **FILIALES JURIDIQUES** : Forme juridique (SARL, SAS, GmbH, LLC, Ltd, Inc, BV)
- **BUREAUX COMMERCIAUX** : Bureaux, agences, succursales (PAS de personnalit√© juridique)
- **PARTENAIRES/DISTRIBUTEURS** : Entreprises tierces

Crit√®res : Pays REQUIS, ville recommand√©e, source requise, si doute ‚Üí `commercial_presence` type="office"

# R√àGLES CRITIQUES

## üîç Classification

**FILIALE JURIDIQUE** ‚Üí `subsidiaries[]` :
- Forme juridique explicite (SA, SAS, SARL, GmbH, LLC, Ltd, Inc, BV)
- **R√àGLE SP√âCIALE** : Si source mentionne explicitement "filiale", "subsidiary", "entit√© juridique", "legal entity" ‚Üí C'EST UNE FILIALE m√™me sans forme juridique visible
  - Ex: "ouvre deux filiales en Allemagne et en Inde" ‚Üí classer en `subsidiaries[]`
  - Ex: "subsidiary in Munich" ‚Üí classer en `subsidiaries[]`

**PR√âSENCE COMMERCIALE** ‚Üí `commercial_presence[]` :
- **office** : Bureau, agence, succursale, usine, centre R&D
- **partner** : Partenaire certifi√©
- **distributor** : Distributeur autoris√©
- **representative** : Agent commercial

**Si doute** ‚Üí `commercial_presence` type="office", confidence: 0.5

**Principe** : **Inclure avec faible confidence > Exclure totalement**

## ‚úÖ ENTIT√âS √Ä INCLURE OBLIGATOIREMENT
**PRINCIPE FONDAMENTAL : Mieux vaut inclure avec faible confidence que exclure totalement**

**ENTIT√âS VALIDES √Ä TOUJOURS INCLURE :**
- **Filiales juridiques** : SAS, GmbH, Inc, Ltd, SARL, LLC, BV
- **Bureaux commerciaux** : offices, branches, agences, succursales
- **Distributeurs officiels** : partners, authorized dealers, revendeurs
- **Usines et centres de production** : manufacturing facilities, plants
- **Centres R&D et laboratoires** : research centers, R&D facilities
- **Repr√©sentants commerciaux** : agents, representatives

**R√àGLE D'INCLUSION ASSOUPLIE :**
- Entit√© mentionn√©e avec pays identifiable ‚Üí INCLURE
- M√™me si info partielles (ville manquante, contacts manquants)
- Confidence faible (0.3-0.6) pour info partielles
- Confidence √©lev√©e (0.7-0.9) pour info compl√®tes

## üè¢ R√àGLE SP√âCIALE POUR SITE OFFICIEL
**ENTIT√âS MENTIONN√âES SUR SITE OFFICIEL :**
- Si entit√© mentionn√©e sur site officiel ‚Üí **confidence: 0.5 (50%) MINIMUM**
- M√™me si info partielles (ville manquante, contacts manquants)
- Toujours inclure avec confidence 0.5-0.6
- Principe : Site officiel = source fiable ‚Üí confidence minimum garantie

**EXEMPLES :**
- "ACOEM India Manufacturing Site" sur acoem.com ‚Üí confidence: 0.5
- "ACOEM R&D Center" sur acoem.com ‚Üí confidence: 0.5
- "Bureau commercial" sur site officiel ‚Üí confidence: 0.5

## üö´ Anti-hallucination
- Ne JAMAIS inventer adresse, ville, t√©l√©phone, email
- **Pays obligatoire** : Sans pays = EXCLURE
- **Ville recommand√©e** : Si absent + pays pr√©sent = ACCEPTER avec `city: null`
- Toute info trac√©e dans texte + `citations[]`
- En cas de doute : `null`

## üìã Extraction filiales juridiques

**Obligatoires** : `legal_name`, `country`
**Recommand√©s** : `city` (ou `null`)
**Optionnels** : `line1`, `postal_code`, `phone`, `email`, `activity`

**G√©ocodage automatique** :
- Si `city` + `country` ‚Üí `latitude`/`longitude` centre-ville
- Si SEULEMENT `country` ‚Üí `latitude`/`longitude` capitale
- Ex: Paris (48.8566, 2.3522), London (51.5074, -0.1278), Berlin (52.5200, 13.4050)

**Sources** : URLs de `citations` - Tier : `official` > `financial_media` > `other`

**Confidence** :
- 0.85-0.95 : Site officiel, SEC, registres
- 0.70-0.85 : Financial DB
- 0.60-0.70 : Presse financi√®re
- 0.50-0.60 : LinkedIn, Crunchbase

**Limites** : Max 50 filiales, max 10 sources/filiale, max 20 notes

## üåç Extraction pr√©sence commerciale

**Obligatoires** : `name`, `type`, `relationship`, `location.country`
**Recommand√©s** : `location.city` (ou `null`)
**Optionnels** : `activity`, `line1`, `postal_code`, `phone`, `email`, `since_year`, `status`

**G√©ocodage** : M√™me r√®gles que filiales

**Confidence** :
- 0.85-0.95 : Site officiel "Nos bureaux/Partenaires"
- 0.70-0.85 : Presse sp√©cialis√©e, annonces officielles
- 0.60-0.70 : Bases professionnelles
- 0.50-0.60 : LinkedIn, mentions

**Limites** : Max 50 pr√©sences, max 10 sources/pr√©sence

## üè≠ INSTRUCTIONS SP√âCIALES POUR USINES ET CENTRES R&D
**ENTIT√âS √Ä TOUJOURS INCLURE :**
- **Usines** : manufacturing facilities, plants, production sites
- **Centres R&D** : research centers, R&D facilities, laboratories
- **Bureaux commerciaux** : offices, branches, commercial offices

**R√àGLES D'INCLUSION :**
- Si mentionn√© avec pays identifiable ‚Üí INCLURE
- M√™me si info partielles (ville manquante, contacts manquants)
- Classer en `commercial_presence` type="office"
- **Confidence 0.4-0.6** pour info partielles
- **Confidence 0.7-0.9** pour info compl√®tes

## üè¢ Si aucune entit√© trouv√©e
Extrais info entreprise principale dans `extraction_summary.main_company_info` :
- `address`, `revenue`, `employees`, `phone`, `email`
- Note : "Aucune filiale ni pr√©sence commerciale trouv√©e"

## ‚ö†Ô∏è Gestion erreurs
Si `status: "error"` :
```json
{
  "company_name": "Nom",
  "parents": [],
  "subsidiaries": [],
  "commercial_presence": [],
  "methodology_notes": ["Erreur: message"],
  "extraction_summary": {"total_found": 0, "total_commercial_presence": 0, "methodology_used": ["Erreur"]}
}
```

## üéØ Validation g√©ographique
V√©rifie coh√©rence pays/ville : Paris (France) ‚â† Paris (Texas, USA)

## ‚úÖ Checklist finale
- [ ] Outil appel√© avec param√®tres corrects ?
- [ ] Status v√©rifi√© ?
- [ ] Distinction filiale vs pr√©sence faite ?
- [ ] Si doute ‚Üí `commercial_presence` type="office", confidence: 0.5 ?
- [ ] Pays identifi√© pour chaque entit√© ?
- [ ] Coordonn√©es g√©ographiques ajout√©es ?
- [ ] Sources mapp√©es depuis `citations` ?
- [ ] Contacts copi√©s exactement (pas invent√©s) ?
- [ ] Principe appliqu√© : Inclure avec faible confidence > Exclure ?
- [ ] Entit√©s site officiel avec confidence minimum 0.5 ?
- [ ] Usines et centres R&D inclus ?

"""

# Configuration OpenAI GPT-4 (initialisation paresseuse)
openai_client = None

def get_openai_client():
    """Initialise le client OpenAI de mani√®re paresseuse."""
    global openai_client
    if openai_client is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.warning("‚ö†Ô∏è OPENAI_API_KEY non d√©finie - le client OpenAI ne sera pas initialis√©")
            return None
        openai_client = AsyncOpenAI(api_key=api_key)
    return openai_client

# Initialisation paresseuse du mod√®le GPT-4
gpt4_llm = None

def get_gpt4_llm():
    """Initialise le mod√®le GPT-4 de mani√®re paresseuse."""
    global gpt4_llm
    if gpt4_llm is None:
        client = get_openai_client()
        if not client:
            return None
        gpt4_llm = OpenAIChatCompletionsModel(
            model="gpt-4o",
            openai_client=client,
        )
    return gpt4_llm


# Sch√©ma de sortie - selon la doc OpenAI Agents SDK
subsidiary_report_schema = AgentOutputSchema(SubsidiaryReport, strict_json_schema=True)


# ==========================================
#   AGENT CARTOGRAPHE SIMPLE
# ==========================================

# Initialisation paresseuse des agents
cartographe_simple = None
cartographe_advanced = None

def get_cartographe_simple():
    """Initialise l'agent cartographe simple de mani√®re paresseuse."""
    global cartographe_simple
    if cartographe_simple is None:
        llm = get_gpt4_llm()
        if not llm:
            return None
        cartographe_simple = Agent(
            name="üó∫Ô∏è Cartographe",
            instructions=CARTOGRAPHE_SIMPLE_PROMPT,
            tools=[subsidiary_search],  # Outil de recherche simple
            output_type=subsidiary_report_schema,
            model=llm,
        )
    return cartographe_simple


# ==========================================
#   AGENT CARTOGRAPHE AVANC√â
# ==========================================

def get_cartographe_advanced():
    """Initialise l'agent cartographe avanc√© de mani√®re paresseuse."""
    global cartographe_advanced
    if cartographe_advanced is None:
        llm = get_gpt4_llm()
        if not llm:
            return None
    cartographe_advanced = Agent(
        name="üó∫Ô∏è Cartographe",
        instructions=CARTOGRAPHE_ADVANCED_PROMPT,
        tools=[research_subsidiaries_with_perplexity],  # Outil de recherche avanc√©
        output_type=subsidiary_report_schema,
                model=llm,
            )
    return cartographe_advanced


# Exportation pour r√©trocompatibilit√© (fonction paresseuse)
def get_subsidiary_extractor():
    """Retourne l'agent cartographe avanc√© de mani√®re paresseuse."""
    agent = get_cartographe_advanced()
    if agent is None:
        # Fallback vers l'agent simple si l'avanc√© n'est pas disponible
        logger.warning("‚ö†Ô∏è Agent avanc√© non disponible, utilisation de l'agent simple")
        return get_cartographe_simple()
    return agent

# Alias pour r√©trocompatibilit√©
subsidiary_extractor = get_subsidiary_extractor


# ==========================================
#   WRAPPER AVEC M√âTRIQUES DE PERFORMANCE
# ==========================================

async def run_cartographe_with_metrics(
    company_context: Any,
    session_id: str = None,
    deep_search: bool = False
) -> Dict[str, Any]:
    """
    Ex√©cute l'agent Cartographe avec m√©triques de performance en temps r√©el.

    Args:
        company_context: Contexte de l'entreprise (dict avec company_name, sector, activities) ou string
        session_id: ID de session pour le suivi temps r√©el
        deep_search: Si True, utilise le pipeline avanc√© (Perplexity). Si False, utilise le pipeline simple (gpt-4o-search)

    Returns:
        Dict contenant les r√©sultats et m√©triques de performance
    """
    # S√©lectionner l'agent selon deep_search
    if deep_search:
        selected_agent = get_cartographe_advanced()
        pipeline_name = "Pipeline Avanc√©"
    else:
        selected_agent = get_cartographe_simple()
        pipeline_name = "Pipeline Simple"
    
    # V√©rifier que l'agent est disponible
    if selected_agent is None:
        logger.error("‚ùå Aucun agent disponible - v√©rifiez la configuration OpenAI")
        return {
            "status": "error",
            "error": "Agent non disponible - v√©rifiez la configuration OpenAI",
            "pipeline_name": pipeline_name
        }

    logger.info(f"üéØ S√©lection pipeline: {pipeline_name}")

    # G√©rer √† la fois dict et string pour r√©trocompatibilit√©
    if isinstance(company_context, dict):
        company_name = company_context.get("company_name", str(company_context))
        input_data = json.dumps(company_context, ensure_ascii=False)
    else:
        company_name = str(company_context)
        input_data = company_name

    # D√©marrer les m√©triques
    agent_name = "üó∫Ô∏è Cartographe"
    agent_metrics = metrics_collector.start_agent(agent_name, session_id or "default")
    
    # D√©marrer le suivi temps r√©el
    from status.manager import status_manager
    real_time_tracker = RealTimeTracker(status_manager)
    
    try:
        # D√©marrer le suivi temps r√©el en arri√®re-plan
        tracking_task = asyncio.create_task(
            real_time_tracker.track_agent_realtime("üó∫Ô∏è Cartographe", session_id or "default", agent_metrics)
        )
        
        # √âtape 1: Initialisation
        init_step = agent_metrics.add_step("Initialisation")
        logger.info(f"üó∫Ô∏è D√©but de cartographie pour: {company_name} ({pipeline_name})")
        init_step.finish(MetricStatus.COMPLETED, {
            "company_name": company_name,
            "pipeline": pipeline_name,
            "deep_search": deep_search
        })

        # √âtape 2: Recherche (nom adapt√© selon le pipeline)
        research_name = "Recherche approfondie" if deep_search else "Recherche rapide"
        research_step = agent_metrics.add_step(research_name)
        research_step.status = MetricStatus.TOOL_CALLING

        # Ex√©cution de l'agent avec suivi des √©tapes
        from agents import Runner
        result = await Runner.run(
            selected_agent,  # ‚Üê Utiliser l'agent s√©lectionn√© selon deep_search
            input_data,
            max_turns=3
        )

        # Capturer les tokens utilis√©s si disponibles (selon la doc OpenAI)
        if hasattr(result, 'context_wrapper') and hasattr(result.context_wrapper, 'usage'):
            try:
                usage = result.context_wrapper.usage

                # R√©cup√©rer le nom du mod√®le (pas l'objet)
                model_obj = getattr(selected_agent, 'model', None)

                # Essayer plusieurs m√©thodes pour extraire le nom du mod√®le
                model_name = 'gpt-4o' if deep_search else 'gpt-4o-search-preview'  # Fallback
                if model_obj:
                    # M√©thode 1 : Attribut 'name'
                    if hasattr(model_obj, 'name'):
                        model_name = model_obj.name
                    # M√©thode 2 : Attribut 'model'
                    elif hasattr(model_obj, 'model'):
                        model_name = model_obj.model
                    # M√©thode 3 : Attribut 'model_name'
                    elif hasattr(model_obj, 'model_name'):
                        model_name = model_obj.model_name
                    # M√©thode 4 : Pour OpenAI models, chercher dans config
                    elif hasattr(model_obj, '_model'):
                        model_name = model_obj._model
                    # M√©thode 5 : Convertir en string et extraire
                    else:
                        str_repr = str(model_obj)
                        if 'model=' in str_repr:
                            model_name = str_repr.split('model=')[1].split(',')[0].strip().strip("'\"")
                        else:
                            model_name = str_repr

                # V√©rifier que usage existe et a les attributs n√©cessaires
                if usage and hasattr(usage, 'input_tokens') and hasattr(usage, 'output_tokens'):
                    token_info = {
                        "model": model_name,
                        "input_tokens": usage.input_tokens,
                        "output_tokens": usage.output_tokens,
                        "total_tokens": getattr(usage, 'total_tokens', usage.input_tokens + usage.output_tokens)
                    }
                else:
                    # Fallback si usage n'a pas les attributs attendus
                    token_info = {
                        "model": model_name,
                        "input_tokens": 0,
                        "output_tokens": 0,
                        "total_tokens": 0
                    }

                # Stocker dans les m√©triques de performance
                agent_metrics.performance_metrics["tokens"] = token_info

                logger.info(
                    f"üí∞ Tokens captur√©s pour {agent_name}: "
                    f"{token_info['input_tokens']} in + {token_info['output_tokens']} out = "
                    f"{token_info['total_tokens']} total (mod√®le: {model_name}, pipeline: {pipeline_name})"
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Impossible de capturer les tokens pour {agent_name}: {e}")
        else:
            logger.warning(f"‚ö†Ô∏è Pas de donn√©es d'usage disponibles pour {agent_name} ({pipeline_name})")

        research_step.finish(MetricStatus.COMPLETED, {
            "research_completed": True,
            "pipeline_used": pipeline_name
        })
        
        # √âtape 3: Structuration des donn√©es
        struct_step = agent_metrics.add_step("Structuration des donn√©es")
        struct_step.status = MetricStatus.PROCESSING
        
        # Extraction des m√©triques - selon la doc OpenAI Agents SDK
        if hasattr(result, 'final_output') and result.final_output:
            output_data = result.final_output
            
            # Selon la doc OpenAI Agents SDK, final_output peut √™tre :
            # 1. Un objet Pydantic directement
            # 2. Un dictionnaire
            # 3. Une cha√Æne JSON
            
            if hasattr(output_data, 'model_dump'):
                # Cas 1: Objet Pydantic (SubsidiaryReport)
                try:
                    output_data = output_data.model_dump()
                    logger.info(f"‚úÖ Objet Pydantic converti en dictionnaire pour {company_name}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Impossible de convertir l'objet Pydantic pour {company_name}: {e}")
                    output_data = None
            elif isinstance(output_data, dict):
                # Cas 2: Dictionnaire d√©j√† structur√©
                logger.info(f"‚úÖ Donn√©es d√©j√† en format dictionnaire pour {company_name}")
                
                # Validation de taille pour √©viter les JSON trop volumineux
                json_str = json.dumps(output_data, ensure_ascii=False)
                if len(json_str) > 10000:  # Limite √† 10KB
                    logger.warning(f"‚ö†Ô∏è JSON trop volumineux ({len(json_str)} caract√®res) pour {company_name}, limitation appliqu√©e")
                    # Limiter le nombre de filiales
                    if 'subsidiaries' in output_data and len(output_data['subsidiaries']) > 10:
                        output_data['subsidiaries'] = output_data['subsidiaries'][:10]
                        output_data['methodology_notes'] = (output_data.get('methodology_notes', []) or [])[:5]
                        logger.info(f"‚úÖ Limitation appliqu√©e: 10 filiales max pour {company_name}")
            elif isinstance(output_data, str):
                # Cas 3: Cha√Æne JSON √† parser
                try:
                    output_data = json.loads(output_data)
                    logger.info(f"‚úÖ JSON pars√© en dictionnaire pour {company_name}")
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå Erreur JSON pour {company_name}: {e}")
                    logger.error(f"üìù Contenu re√ßu: {output_data[:500]}...")
                    # üîß FALLBACK : Cr√©er un objet vide en cas d'√©chec JSON
                    output_data = {
                        "company_name": company_name,
                        "subsidiaries": [],
                        "commercial_presence": [],
                        "methodology_notes": [f"Erreur de parsing JSON: {str(e)}"]
                    }
                    logger.warning(f"‚ö†Ô∏è Fallback appliqu√© pour {company_name}")
            else:
                logger.warning(f"‚ö†Ô∏è Format de sortie inattendu pour {company_name}: {type(output_data)}")
                output_data = None
            
            if isinstance(output_data, dict):
                subsidiaries_count = len(output_data.get('subsidiaries', []))
                commercial_presence_count = len(output_data.get('commercial_presence', []))
                methodology_notes = output_data.get('methodology_notes', [])
                
                # üîß FIX: Mapper les citations depuis les sources des entit√©s
                all_sources = []
                for sub in output_data.get('subsidiaries', []):
                    all_sources.extend(sub.get('sources', []))
                for pres in output_data.get('commercial_presence', []):
                    all_sources.extend(pres.get('sources', []))
                
                # Compter les URLs uniques
                unique_urls = set([s.get('url') for s in all_sources if s.get('url')])
                citations_count = len(unique_urls)
                
                logger.info(f"üìä Cartographie {company_name}: {subsidiaries_count} filiales, {commercial_presence_count} pr√©sences commerciales, {citations_count} sources uniques")
                
                # D√©tection d'erreurs dans les notes
                has_errors = any('erreur' in note.lower() or 'error' in note.lower() 
                               for note in (methodology_notes or []))
                
                # Calcul du score de confiance am√©lior√©
                total_entities = subsidiaries_count + commercial_presence_count
                if total_entities > 0 and not has_errors:
                    confidence_score = 0.9
                elif total_entities > 0 and has_errors:
                    confidence_score = 0.6
                else:
                    confidence_score = 0.3
                
                # M√©triques de qualit√© enrichies
                agent_metrics.quality_metrics = {
                    "subsidiaries_found": subsidiaries_count,
                    "commercial_presence_found": commercial_presence_count,
                    "total_entities": total_entities,
                    "citations_count": citations_count,
                    "confidence_score": confidence_score,
                    "has_errors": has_errors,
                    "methodology_notes_count": len(methodology_notes) if methodology_notes else 0
                }
                
                # M√©triques de performance (MISE √Ä JOUR au lieu d'√©crasement pour garder "tokens")
                agent_metrics.performance_metrics.update({
                    "total_duration_ms": int((time.time() - agent_metrics.start_time) * 1000),
                    "steps_completed": len(agent_metrics.steps),
                    "success_rate": 1.0 if not has_errors else 0.0
                })
                
                struct_step.finish(MetricStatus.COMPLETED, {
                    "subsidiaries_count": subsidiaries_count,
                    "citations_count": citations_count,
                    "confidence_score": confidence_score
                })
                
                # Finalisation
                final_step = agent_metrics.add_step("Finalisation")
                final_step.finish(MetricStatus.COMPLETED)
                
                # Terminer les m√©triques
                agent_metrics.finish(MetricStatus.COMPLETED if not has_errors else MetricStatus.ERROR)
                
                # Annuler le suivi temps r√©el et envoyer les m√©triques finales
                tracking_task.cancel()
                try:
                    await tracking_task
                except asyncio.CancelledError:
                    pass
                
                await real_time_tracker.send_final_metrics("üó∫Ô∏è Cartographe", session_id or "default", agent_metrics)
                
                logger.info(f"‚úÖ Cartographie termin√©e pour {company_name}: {subsidiaries_count} filiales, {agent_metrics.total_duration_ms}ms")
                
                return {
                    "result": output_data,
                    "status": "success" if not has_errors else "error",
                    "duration_ms": agent_metrics.total_duration_ms,
                    "subsidiaries_count": subsidiaries_count,
                    "has_errors": has_errors,
                    "methodology_notes": methodology_notes or [],
                    "metrics": agent_metrics.to_dict()
                }
            else:
                # Cas o√π final_output n'est pas un dict ou est None apr√®s parsing
                struct_step.finish(MetricStatus.COMPLETED, {"output_type": type(output_data).__name__ if output_data else "None"})
                
                # Finalisation
                final_step = agent_metrics.add_step("Finalisation")
                final_step.finish(MetricStatus.COMPLETED)
                
                # Terminer les m√©triques avec succ√®s (on a un r√©sultat, m√™me si format inattendu)
                agent_metrics.finish(MetricStatus.COMPLETED)
                
                # Annuler le suivi temps r√©el et envoyer les m√©triques finales
                tracking_task.cancel()
                try:
                    await tracking_task
                except asyncio.CancelledError:
                    pass
                
                await real_time_tracker.send_final_metrics("üó∫Ô∏è Cartographe", session_id or "default", agent_metrics)
                
                if output_data is None:
                    logger.info(f"‚ÑπÔ∏è Aucune donn√©e pars√©e pour {company_name} - format OpenAI Agents SDK standard")
                else:
                    logger.warning(f"‚ö†Ô∏è Format de sortie inattendu pour {company_name}: {type(output_data).__name__}")
                
                return {
                    "result": result.final_output,
                    "status": "success",
                    "duration_ms": agent_metrics.total_duration_ms,
                    "subsidiaries_count": 0,
                    "has_errors": False,
                    "methodology_notes": ["Format de sortie trait√© avec succ√®s"],
                    "metrics": agent_metrics.to_dict()
                }
        else:
            struct_step.finish(MetricStatus.ERROR, {"error": "Pas de r√©sultat final"})
            agent_metrics.finish(MetricStatus.ERROR, "Pas de r√©sultat final")
            
            # Annuler le suivi temps r√©el et envoyer les m√©triques finales
            tracking_task.cancel()
            try:
                await tracking_task
            except asyncio.CancelledError:
                pass
            
            await real_time_tracker.send_final_metrics("üó∫Ô∏è Cartographe", session_id or "default", agent_metrics)
            
            logger.error(f"‚ùå Pas de r√©sultat final pour {company_name}")
            return {
                "result": None,
                "status": "error",
                "duration_ms": agent_metrics.total_duration_ms,
                "subsidiaries_count": 0,
                "has_errors": True,
                "methodology_notes": ["Pas de r√©sultat final"],
                "metrics": agent_metrics.to_dict()
            }
            
    except Exception as e:
        # Marquer l'√©tape en erreur
        current_step = agent_metrics.get_current_step()
        if current_step:
            current_step.finish(MetricStatus.ERROR, {"error": str(e)})
        
        agent_metrics.finish(MetricStatus.ERROR, str(e))
        
        # Annuler le suivi temps r√©el et envoyer les m√©triques finales
        tracking_task.cancel()
        try:
            await tracking_task
        except asyncio.CancelledError:
            pass
        
        await real_time_tracker.send_final_metrics("üó∫Ô∏è Cartographe", session_id or "default", agent_metrics)
        
        logger.error(f"‚ùå Erreur lors de la cartographie pour {company_name}: {str(e)}", exc_info=True)
        
        return {
            "result": None,
            "status": "error",
            "duration_ms": agent_metrics.total_duration_ms,
            "subsidiaries_count": 0,
            "has_errors": True,
            "methodology_notes": [f"Erreur d'ex√©cution: {str(e)}"],
            "error": str(e),
            "metrics": agent_metrics.to_dict()
        }